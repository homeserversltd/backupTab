#!/usr/bin/env python3
"""
HOMESERVER Enhanced Backup CLI Utility
Copyright (C) 2024 HOMESERVER LLC

Enhanced backup utility with modular provider system for rigorous testing.
"""

import os
import sys
import json
import argparse
import tempfile
import shutil
import tarfile
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

# Add src to path for imports
current_dir = Path(__file__).parent
src_dir = current_dir / "src"
sys.path.insert(0, str(src_dir))

try:
    # Try relative import first (when used as module)
    from .src.providers import get_provider, PROVIDERS
    from .src.utils import get_logger, CronManager, ConfigManager, EncryptionManager
    from .src.utils.config_manager import BACKUP_BASE_DIR
except ImportError:
    try:
        # Fall back to absolute import (when run as script)
        from src.providers import get_provider, PROVIDERS
        from src.utils import get_logger, CronManager, ConfigManager, EncryptionManager
        from src.utils.config_manager import BACKUP_BASE_DIR
    except ImportError as e:
        print(f"ERROR: Failed to import providers: {e}")
        print(f"Current directory: {current_dir}")
        print(f"Looking for providers in: {src_dir}")
        sys.exit(1)

class EnhancedBackupCLI:
    """Enhanced backup CLI with modular provider system."""
    
    def __init__(self, config_file: Optional[str] = None):
        # Use system config by default, fallback to template
        if config_file is None:
            system_config = "/etc/backupTab/settings.json"
            template_config = "src/config/settings.json"
            self.config_file = system_config if os.path.exists(system_config) else template_config
        else:
            self.config_file = config_file
        self.temp_dir = Path("/tmp/homeserver-backup-cli-enhanced")
        self.backup_dir = Path(BACKUP_BASE_DIR)
        self.state_file = Path("/opt/homeserver-backup/backup_state.json")
        
        # Initialize utilities
        self.logger = get_logger()
        self.cron_manager = CronManager()
        self.config_manager = ConfigManager(self.config_file)
        self.encryption_manager = EncryptionManager()
        
        # Ensure directories exist
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # Ensure state directory exists
        self.state_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Load configuration
        self.config = self.config_manager.load_config()
        
        # Configure file logging
        if 'logging' in self.config:
            self.logger.configure_file_logging(self.config['logging'])
        
        # Initialize providers
        self.providers = {}
        self._initialize_providers()
    
    
    def _initialize_providers(self):
        """Initialize enabled providers."""
        for provider_name, provider_config in self.config["providers"].items():
            if provider_config.get("enabled", False):
                try:
                    provider = get_provider(provider_name, provider_config)
                    self.providers[provider_name] = provider
                    print(f"Initialized provider: {provider_name}")
                except Exception as e:
                    print(f"WARNING: Failed to initialize provider {provider_name}: {e}")
    
    def _update_backup_state(self, backup_path: Optional[Path], backup_type: str = 'manual'):
        """Update the backup state file with last backup timestamp and size."""
        try:
            # Get backup size
            backup_size_bytes = 0
            backup_size_display = "Unknown"
            
            if backup_path and backup_path.exists():
                backup_size_bytes = backup_path.stat().st_size
                
                # Convert to human-readable format
                units = ['B', 'KB', 'MB', 'GB', 'TB']
                unit_index = 0
                size_value = float(backup_size_bytes)
                
                while size_value >= 1024 and unit_index < len(units) - 1:
                    size_value /= 1024
                    unit_index += 1
                
                backup_size_display = f"{size_value:.1f} {units[unit_index]}"
            
            # Current timestamp
            current_timestamp = datetime.now().isoformat()
            
            # Load existing state or create new
            state = {}
            if self.state_file.exists():
                try:
                    with open(self.state_file, 'r') as f:
                        state = json.load(f)
                except Exception as e:
                    self.logger.warning(f"Failed to load existing state: {e}")
                    state = {}
            
            # Initialize backup_history if it doesn't exist
            if 'backup_history' not in state:
                state['backup_history'] = []
            
            # Update last backup information
            state['last_backup'] = current_timestamp
            state['last_backup_size_bytes'] = backup_size_bytes
            state['last_backup_size_display'] = backup_size_display
            state['last_backup_type'] = backup_type
            
            # If this is a daily/scheduled backup, also update last_daily_backup
            if backup_type == 'daily' or backup_type == 'scheduled':
                state['last_daily_backup'] = current_timestamp
            
            # Add to backup history (keep last 100 entries)
            backup_entry = {
                'timestamp': current_timestamp,
                'type': backup_type,
                'size_bytes': backup_size_bytes,
                'size_display': backup_size_display,
                'success': True
            }
            state['backup_history'].append(backup_entry)
            if len(state['backup_history']) > 100:
                state['backup_history'] = state['backup_history'][-100:]
            
            # Write state file
            with open(self.state_file, 'w') as f:
                json.dump(state, f, indent=2)
            
            self.logger.info(f"Backup state updated: {backup_type} backup at {current_timestamp}, size: {backup_size_display}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to update backup state: {e}")
            return False
    
    def _create_backup_metadata(self, backup_items: List[str], timestamp: str) -> Dict[str, Any]:
        """Create metadata for backup package."""
        metadata = {
            "timestamp": timestamp,
            "backup_name": f"homeserver_backup_{timestamp}",
            "items": [],
            "created_at": datetime.now().isoformat(),
            "homeserver_version": "1.0.0",
            "cli_version": "1.0.0-enhanced",
            "providers": list(self.providers.keys())
        }
        
        for item in backup_items:
            item_path = Path(item)
            if item_path.exists():
                stat = item_path.stat()
                item_info = {
                    "source_path": str(item_path),
                    "backup_name": item_path.name,
                    "type": "directory" if item_path.is_dir() else "file",
                    "size": stat.st_size,
                    "permissions": oct(stat.st_mode)[-3:],
                    "owner": f"{stat.st_uid}:{stat.st_gid}",
                    "mtime": datetime.fromtimestamp(stat.st_mtime).isoformat()
                }
                metadata["items"].append(item_info)
        
        return metadata
    
    def _create_backup_package(self, backup_items: List[str], timestamp: str) -> Optional[Path]:
        """Create backup package with metadata."""
        package_name = f"homeserver_backup_{timestamp}"
        package_path = self.temp_dir / f"{package_name}.tar.gz"
        
        print(f"Creating backup package: {package_name}")
        
        # Create metadata
        metadata = self._create_backup_metadata(backup_items, timestamp)
        
        # Create tar.gz archive
        with tarfile.open(package_path, "w:gz", compresslevel=self.config["compression"]["level"]) as tar:
            for item in backup_items:
                item_path = Path(item)
                if item_path.exists():
                    tar.add(item, arcname=item_path.name)
                    print(f"  Added: {item}")
                else:
                    print(f"  WARNING: Item not found: {item}")
            
            # Add metadata file to archive
            metadata_file = self.temp_dir / "backup_metadata.json"
            with open(metadata_file, "w") as f:
                json.dump(metadata, f, indent=2)
            tar.add(metadata_file, arcname="backup_metadata.json")
            metadata_file.unlink()
        
        print(f"Created backup package: {package_path}")
        return package_path
    
    def _encrypt_backup(self, package_path: Path) -> Optional[Path]:
        """Encrypt backup package with FAK."""
        if not self.config["encryption"]["enabled"]:
            return package_path
        
        print("Encrypting backup package...")
        
        if not self.encryption_manager.is_encryption_available():
            print("ERROR: FAK key not available, cannot encrypt backup")
            return None
        
        encrypted_path = self.encryption_manager.encrypt_file(package_path)
        if not encrypted_path:
            print("ERROR: Failed to encrypt backup package")
            return None
        
        # Clean up unencrypted package
        package_path.unlink()
        
        print(f"Encrypted backup package: {encrypted_path}")
        return encrypted_path
    
    def create_backup(self, items: Optional[List[str]] = None) -> Optional[Path]:
        """Create a new backup and upload to all enabled providers."""
        backup_items = items or self.config["backup_items"]
        timestamp = datetime.now().strftime(self.config["timestamp_chains"]["format"])
        
        self.logger.log_backup_start(backup_items, list(self.providers.keys()))
        
        # Create backup package
        package_path = self._create_backup_package(backup_items, timestamp)
        if not package_path:
            self.logger.log_backup_failure("Failed to create backup package")
            return None
        
        # Encrypt if enabled (for cloud providers only)
        encrypted_path = None
        if self.config["encryption"]["enabled"]:
            encrypted_path = self._encrypt_backup(package_path)
            if not encrypted_path:
                self.logger.log_backup_failure("Failed to encrypt backup package")
                return None
            self.logger.info("Backup package encrypted for cloud providers")
        else:
            self.logger.info("Encryption disabled - all providers will receive unencrypted data")
        
        # Upload to all enabled providers
        upload_results = {}
        for provider_name, provider in self.providers.items():
            self.logger.info(f"Processing with {provider_name}...")
            
            # Choose which version to upload based on provider type
            if provider_name == "local":
                # Local provider gets unencrypted version
                upload_path = package_path
                self.logger.info("Using unencrypted package for local provider")
            else:
                # Cloud providers get encrypted version (if encryption is enabled)
                upload_path = encrypted_path if encrypted_path else package_path
                if encrypted_path:
                    self.logger.info(f"Using encrypted package for {provider_name} provider")
                else:
                    self.logger.info(f"Using unencrypted package for {provider_name} provider (encryption disabled)")
            
            # Upload to the provider
            if provider_name == "local":
                # Local provider handles tarball creation internally
                backup_path = provider.create_backup(backup_items, timestamp)
                success = backup_path is not None
                if success:
                    self.logger.info(f"Local backup created: {backup_path}")
            else:
                # Cloud providers upload the appropriate version (encrypted or unencrypted)
                # Use consistent filename to overwrite previous backups (space-saving)
                remote_name = "homeserver_backup_latest.tar.gz"
                if encrypted_path and upload_path == encrypted_path:
                    remote_name = "homeserver_backup_latest.tar.gz.enc"  # Mark encrypted files
                success = provider.upload(upload_path, remote_name)
            
            upload_results[provider_name] = success
            self.logger.log_provider_operation(provider_name, "upload", success)
        
        # Move to local backup directory (only if not using local provider)
        if "local" not in self.providers or not upload_results.get("local", False):
            local_path = self.backup_dir / package_path.name
            shutil.move(str(package_path), str(local_path))
            self.logger.log_backup_success(str(local_path), upload_results)
            
            # Increment backup count in settings.json
            try:
                success = self.config_manager.increment_backup_count()
                if success:
                    self.logger.info("Backup count incremented successfully")
                else:
                    self.logger.warning("Failed to increment backup count, but backup was successful")
            except Exception as count_error:
                self.logger.warning(f"Failed to increment backup count: {count_error}")
            
            # Update backup state file with last backup timestamp and size
            self._update_backup_state(local_path, backup_type='manual')
            
            return local_path
        else:
            # Local provider already handled storage, clean up temp package
            if package_path.exists():
                package_path.unlink()
            self.logger.log_backup_success("NAS storage", upload_results)
            
            # Increment backup count in settings.json
            try:
                success = self.config_manager.increment_backup_count()
                if success:
                    self.logger.info("Backup count incremented successfully")
                else:
                    self.logger.warning("Failed to increment backup count, but backup was successful")
            except Exception as count_error:
                self.logger.warning(f"Failed to increment backup count: {count_error}")
            
            # Update backup state file with last backup timestamp and size
            # backup_path was set earlier in the loop when processing local provider
            self._update_backup_state(backup_path, backup_type='manual')
            
            return None  # Local provider returns its own path
    
    def list_backups(self, provider_name: Optional[str] = None) -> List[Dict[str, Any]]:
        """List available backups from specified provider or all providers."""
        all_backups = []
        
        if provider_name:
            if provider_name in self.providers:
                provider = self.providers[provider_name]
                backups = provider.list_files()
                for backup in backups:
                    backup['provider'] = provider_name
                all_backups.extend(backups)
            else:
                print(f"ERROR: Provider {provider_name} not available")
        else:
            # List from all providers
            for prov_name, provider in self.providers.items():
                backups = provider.list_files()
                for backup in backups:
                    backup['provider'] = prov_name
                all_backups.extend(backups)
        
        return sorted(all_backups, key=lambda x: x.get('mtime', 0), reverse=True)
    
    def test_providers(self) -> Dict[str, bool]:
        """Test all enabled providers."""
        results = {}
        
        for provider_name, provider in self.providers.items():
            print(f"Testing {provider_name}...")
            success = provider.test_connection()
            results[provider_name] = success
            if success:
                print(f"  ✓ {provider_name} connection successful")
            else:
                print(f"  ✗ {provider_name} connection failed")
        
        return results
    
    def download_backup(self, backup_name: str, provider_name: str, local_path: Optional[str] = None) -> bool:
        """Download backup from specified provider."""
        if provider_name not in self.providers:
            print(f"ERROR: Provider {provider_name} not available")
            return False
        
        if not local_path:
            local_path = self.temp_dir / backup_name
        
        provider = self.providers[provider_name]
        success = provider.download(backup_name, Path(local_path))
        
        if success:
            print(f"Downloaded {backup_name} from {provider_name} to {local_path}")
        else:
            print(f"Failed to download {backup_name} from {provider_name}")
        
        return success
    
    def test_backup_cycle(self, items: Optional[List[str]] = None) -> bool:
        """Test complete backup cycle: create, upload, download, verify."""
        print("Testing complete backup cycle...")
        
        # Create backup
        backup_path = self.create_backup(items)
        if not backup_path:
            print("ERROR: Failed to create backup")
            return False
        
        backup_name = backup_path.name
        
        # Test download from each provider
        for provider_name, provider in self.providers.items():
            print(f"Testing download from {provider_name}...")
            test_path = self.temp_dir / f"test_{provider_name}_{backup_name}"
            
            if provider.download(backup_name, test_path):
                print(f"  ✓ Download from {provider_name} successful")
                # Verify file exists and has content
                if test_path.exists() and test_path.stat().st_size > 0:
                    print(f"  ✓ File verification successful")
                else:
                    print(f"  ✗ File verification failed")
                test_path.unlink()  # Clean up
            else:
                print(f"  ✗ Download from {provider_name} failed")
        
        print("Backup cycle test completed")
        return True
    
    def set_provider_credentials(self, provider_name: str, username: str, password: str) -> bool:
        """Set credentials for a specific provider using keyman integration."""
        from src.utils.keyman_integration import KeymanIntegration
        
        # Initialize keyman integration
        keyman = KeymanIntegration()
        
        # Store credentials in keyman vault
        success = keyman.create_service_credentials(provider_name, username, password)
        
        if not success:
            print(f"ERROR: Failed to store credentials in keyman vault for {provider_name}")
            return False
        
        # Update non-sensitive provider configuration
        updates = {}
        
        # Handle provider-specific non-sensitive config
        if provider_name == "backblaze":
            updates["container"] = "homeServer-serverGenesis"  # Set correct bucket name
            updates["bucket"] = "homeServer-serverGenesis"  # Backblaze provider uses 'bucket' field
            updates["keyman_integrated"] = True
            updates["keyman_service_name"] = provider_name
        elif provider_name == "aws_s3":
            updates["keyman_integrated"] = True
            updates["keyman_service_name"] = provider_name
        elif provider_name == "google_cloud_storage":
            # Google Cloud Storage uses service account key, not username/password
            print("NOTE: Google Cloud Storage uses service account key authentication")
            print("Make sure you have downloaded service account key from Google Cloud Console")
            updates["keyman_integrated"] = True
            updates["keyman_service_name"] = provider_name
        
        # Update provider config with non-sensitive settings
        if updates:
            config_success = self.config_manager.update_provider_config(provider_name, updates)
            if not config_success:
                print(f"WARNING: Failed to update provider config for {provider_name}")
        
        self.logger.log_credential_operation(provider_name, "set", True)
        print(f"Credentials stored in keyman vault for {provider_name}")
        return True
    
    def set_provider_credentials_json(self, provider_name: str, credentials_json: str) -> bool:
        """Set credentials JSON content for a specific provider."""
        try:
            # Validate JSON format
            import json
            parsed_json = json.loads(credentials_json)
            
            # Write credentials file
            credentials_file = f"{provider_name}_credentials.json"
            credentials_path = Path(credentials_file)
            
            with open(credentials_path, 'w') as f:
                json.dump(parsed_json, f, indent=2)
            
            # Update provider config with credentials file path
            updates = {"credentials_file": credentials_file}
            success = self.config_manager.update_provider_config(provider_name, updates)
            
            if success:
                self.logger.log_credential_operation(provider_name, "set_credentials_json", True)
                print(f"Credentials JSON updated for {provider_name}")
                print(f"Credentials file saved as: {credentials_file}")
                return True
            else:
                print(f"ERROR: Provider '{provider_name}' not found")
                return False
                
        except json.JSONDecodeError as e:
            print(f"ERROR: Invalid JSON format: {e}")
            return False
        except Exception as e:
            print(f"ERROR: Failed to save credentials: {e}")
            return False
    
    def get_provider_credentials(self, provider_name: str) -> Optional[Dict[str, str]]:
        """Get credentials for a specific provider from keyman vault."""
        from src.utils.keyman_integration import KeymanIntegration
        
        # Initialize keyman integration
        keyman = KeymanIntegration()
        
        # Check if provider is configured in keyman
        if not keyman.service_configured(provider_name):
            print(f"ERROR: Provider '{provider_name}' not configured in keyman vault")
            return None
        
        # Get credentials from keyman
        credentials = keyman.get_service_credentials(provider_name)
        
        if not credentials:
            print(f"ERROR: Failed to retrieve credentials from keyman vault for {provider_name}")
            return None
        
        return credentials
    
    def enable_provider(self, provider_name: str) -> bool:
        """Enable a specific provider."""
        success = self.config_manager.enable_provider(provider_name)
        
        if success:
            self.logger.info(f"Provider '{provider_name}' enabled")
            print(f"Provider '{provider_name}' enabled")
        else:
            print(f"ERROR: Provider '{provider_name}' not found")
        
        return success
    
    def disable_provider(self, provider_name: str) -> bool:
        """Disable a specific provider."""
        success = self.config_manager.disable_provider(provider_name)
        
        if success:
            self.logger.info(f"Provider '{provider_name}' disabled")
            print(f"Provider '{provider_name}' disabled")
        else:
            print(f"ERROR: Provider '{provider_name}' not found")
        
        return success
    
    def set_backup_schedule(self, schedule: str) -> bool:
        """Set the backup cron schedule."""
        success = self.cron_manager.set_schedule(schedule)
        if success:
            print(f"Backup schedule updated to: {schedule}")
        else:
            print(f"ERROR: Failed to set backup schedule")
        return success
    
    def get_backup_schedule(self) -> Optional[str]:
        """Get the current backup cron schedule."""
        schedule = self.cron_manager.get_schedule()
        if schedule:
            print(f"Current backup schedule: {schedule}")
        else:
            print("No backup schedule found")
        return schedule
    
    def disable_backup_schedule(self) -> bool:
        """Disable the backup cron schedule."""
        success = self.cron_manager.disable_schedule()
        if success:
            print("Backup schedule disabled")
        else:
            print("ERROR: Failed to disable backup schedule")
        return success
    
    def enable_backup_schedule(self, schedule: str = "0 2 * * *") -> bool:
        """Enable the backup cron schedule with default daily at 2 AM."""
        return self.set_backup_schedule(schedule)
    
    def set_provider_config(self, provider_name: str, key: str, value: str) -> bool:
        """Set a specific configuration value for a provider."""
        # Convert string values to appropriate types
        if value.lower() in ['true', 'false']:
            value = value.lower() == 'true'
        elif value.lower() == 'null':
            value = None
        elif value.isdigit():
            value = int(value)
        elif value.replace('.', '', 1).isdigit():
            value = float(value)
        
        updates = {key: value}
        success = self.config_manager.update_provider_config(provider_name, updates)
        
        if success:
            self.logger.info(f"Updated {provider_name} config: {key} = {value}")
            print(f"Updated {provider_name} config: {key} = {value}")
        else:
            print(f"ERROR: Provider '{provider_name}' not found")
        
        return success
    
    def get_provider_config(self, provider_name: str) -> Optional[Dict[str, Any]]:
        """Get configuration for a specific provider."""
        provider_config = self.config_manager.get_provider_config(provider_name)
        
        if not provider_config:
            print(f"ERROR: Provider '{provider_name}' not found")
            return None
        
        return provider_config
    
    def deploy_cron_job(self, schedule: str) -> bool:
        """Deploy cron job with the specified schedule using backup service."""
        print(f"Deploying cron job with schedule: {schedule}")
        
        try:
            # Use the backup service for deployment
            from src.service.backup_service import BackupService
            service = BackupService(self.config_file)
            result = service.deploy_cron_schedule(schedule)
            
            if result["success"]:
                print(f"Cron job deployed successfully: {result['message']}")
                print(f"Cron file: {result['cron_file']}")
                return True
            else:
                print(f"ERROR: {result['error']}")
                return False
                
        except Exception as e:
            print(f"ERROR: Failed to deploy cron job: {e}")
            return False
    
    def remove_cron_job(self) -> bool:
        """Remove the cron job completely using backup service."""
        print("Removing cron job...")
        
        try:
            # Use the backup service for removal
            from src.service.backup_service import BackupService
            service = BackupService(self.config_file)
            result = service.remove_cron_schedule()
            
            if result["success"]:
                print(f"Cron job removed successfully: {result['message']}")
                return True
            else:
                print(f"ERROR: {result['error']}")
                return False
                
        except Exception as e:
            print(f"ERROR: Failed to remove cron job: {e}")
            return False
    
    def get_cron_job_status(self) -> Dict[str, Any]:
        """Get comprehensive cron job status using backup service."""
        try:
            # Use the backup service for status
            from src.service.backup_service import BackupService
            service = BackupService(self.config_file)
            result = service.get_cron_status()
            
            if result["success"]:
                status = result["status"]
                print(f"Cron Job Status:")
                print(f"  Enabled: {status['enabled']}")
                print(f"  Schedule: {status['schedule'] or 'None'}")
                print(f"  Cron File: {status['cron_file']}")
                print(f"  File Exists: {status['exists']}")
                print(f"  Backup Script: {status['backup_script']}")
                print(f"  Script Executable: {status['script_executable']}")
                return status
            else:
                print(f"ERROR: {result['error']}")
                return {"error": result["error"]}
                
        except Exception as e:
            print(f"ERROR: Failed to get cron status: {e}")
            return {"error": str(e)}
    
    def list_keyman_services(self) -> List[str]:
        """List all configured keyman services."""
        from src.utils.keyman_integration import KeymanIntegration
        
        keyman = KeymanIntegration()
        services = keyman.get_configured_services()
        
        if services:
            print("Configured keyman services:")
            for service in services:
                print(f"  {service}")
        else:
            print("No keyman services configured")
        
        return services
    
    def remove_provider_credentials(self, provider_name: str) -> bool:
        """Remove credentials for a provider from keyman vault."""
        from src.utils.keyman_integration import KeymanIntegration
        
        keyman = KeymanIntegration()
        
        # Check if provider is configured
        if not keyman.service_configured(provider_name):
            print(f"ERROR: Provider '{provider_name}' not configured in keyman vault")
            return False
        
        # Remove credentials
        success = keyman.delete_service_credentials(provider_name)
        
        if success:
            print(f"Credentials removed from keyman vault for {provider_name}")
        else:
            print(f"ERROR: Failed to remove credentials for {provider_name}")
        
        return success
    
    def test_keyman_credentials(self, provider_name: str) -> bool:
        """Test keyman credentials for a provider."""
        from src.utils.keyman_integration import KeymanIntegration
        
        keyman = KeymanIntegration()
        
        # Check if provider is configured
        if not keyman.service_configured(provider_name):
            print(f"ERROR: Provider '{provider_name}' not configured in keyman vault")
            return False
        
        # Test credential retrieval
        credentials = keyman.get_service_credentials(provider_name)
        
        if credentials:
            print(f"✓ Keyman credentials accessible for {provider_name}")
            print(f"  Username: {credentials.get('username', 'N/A')}")
            print(f"  Password: {'*' * len(credentials.get('password', '')) if credentials.get('password') else 'N/A'}")
            return True
        else:
            print(f"✗ Failed to retrieve keyman credentials for {provider_name}")
            return False

def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(description="HOMESERVER Enhanced Backup CLI Utility")
    parser.add_argument("--config", "-c", help="Configuration file path")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    
    # Add note about future developments
    parser.epilog = "Note: Google Cloud Storage and AWS S3 providers are future developments and currently disabled. Only Local and Backblaze providers are fully functional."
    
    subparsers = parser.add_subparsers(dest="command", help="Available commands")
    
    # Create backup command
    create_parser = subparsers.add_parser("create", help="Create a new backup")
    create_parser.add_argument("--items", "-i", nargs="+", help="Items to backup")
    
    # List backups command
    list_parser = subparsers.add_parser("list", help="List available backups")
    list_parser.add_argument("--provider", "-p", help="Specific provider to list from")
    
    # Test providers command
    subparsers.add_parser("test-providers", help="Test all enabled providers")
    
    # Download backup command
    download_parser = subparsers.add_parser("download", help="Download backup from provider")
    download_parser.add_argument("backup_name", help="Name of backup to download")
    download_parser.add_argument("--provider", "-p", required=True, help="Provider to download from")
    download_parser.add_argument("--to", "-t", help="Local path to save to")
    
    # Test backup cycle command
    test_parser = subparsers.add_parser("test-cycle", help="Test complete backup cycle")
    test_parser.add_argument("--items", "-i", nargs="+", help="Items to backup")
    
    # List available providers
    subparsers.add_parser("list-providers", help="List available providers (some are future developments)")
    
    # Set provider credentials command
    set_creds_parser = subparsers.add_parser("set-credentials", help="Set credentials for a provider")
    set_creds_parser.add_argument("provider", help="Provider name")
    set_creds_parser.add_argument("--username", "-u", required=True, help="Username/access key")
    set_creds_parser.add_argument("--password", "-p", required=True, help="Password/secret key")
    
    # Set provider credentials JSON command
    set_creds_json_parser = subparsers.add_parser("set-credentials-json", help="Set credentials JSON content for a provider")
    set_creds_json_parser.add_argument("provider", help="Provider name")
    set_creds_json_parser.add_argument("--json", "-j", required=True, help="Credentials JSON content")
    
    # Get provider credentials command
    get_creds_parser = subparsers.add_parser("get-credentials", help="Get credentials for a provider")
    get_creds_parser.add_argument("provider", help="Provider name")
    
    # Keyman-specific commands
    subparsers.add_parser("list-keyman-services", help="List all configured keyman services")
    
    remove_creds_parser = subparsers.add_parser("remove-credentials", help="Remove credentials from keyman vault")
    remove_creds_parser.add_argument("provider", help="Provider name")
    
    test_keyman_parser = subparsers.add_parser("test-keyman", help="Test keyman credentials for a provider")
    test_keyman_parser.add_argument("provider", help="Provider name")
    
    # Enable provider command
    enable_parser = subparsers.add_parser("enable-provider", help="Enable a provider")
    enable_parser.add_argument("provider", help="Provider name")
    
    # Disable provider command
    disable_parser = subparsers.add_parser("disable-provider", help="Disable a provider")
    disable_parser.add_argument("provider", help="Provider name")
    
    # Set backup schedule command
    schedule_parser = subparsers.add_parser("set-schedule", help="Set backup cron schedule")
    schedule_parser.add_argument("schedule", help="Cron schedule (e.g., '0 2 * * *' for daily at 2 AM)")
    
    # Get backup schedule command
    subparsers.add_parser("get-schedule", help="Get current backup schedule")
    
    # Enable backup schedule command
    enable_schedule_parser = subparsers.add_parser("enable-schedule", help="Enable backup schedule")
    enable_schedule_parser.add_argument("--schedule", "-s", default="0 2 * * *", help="Cron schedule (default: daily at 2 AM)")
    
    # Disable backup schedule command
    subparsers.add_parser("disable-schedule", help="Disable backup schedule")
    
    # Self-contained installer command
    install_parser = subparsers.add_parser("install", help="Install backup system with virtual environment")
    install_parser.add_argument("--force", action="store_true", help="Force installation")
    
    # Uninstall command
    uninstall_parser = subparsers.add_parser("uninstall", help="Uninstall backup system")
    
    # Set provider config command
    set_config_parser = subparsers.add_parser("set-config", help="Set configuration for a provider")
    set_config_parser.add_argument("provider", help="Provider name")
    set_config_parser.add_argument("key", help="Configuration key")
    set_config_parser.add_argument("value", help="Configuration value")
    
    # Get provider config command
    get_config_parser = subparsers.add_parser("get-config", help="Get configuration for a provider")
    get_config_parser.add_argument("provider", help="Provider name")
    
    # Deploy cron job command
    deploy_cron_parser = subparsers.add_parser("deploy-cron", help="Deploy cron job with schedule")
    deploy_cron_parser.add_argument("schedule", help="Cron schedule (e.g., '0 2 * * *' for daily at 2 AM)")
    
    # Remove cron job command
    subparsers.add_parser("remove-cron", help="Remove cron job")
    
    # Get cron status command
    subparsers.add_parser("cron-status", help="Get cron job status")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Initialize CLI
    cli = EnhancedBackupCLI(args.config)
    
    try:
        if args.command == "create":
            cli.create_backup(args.items)
        elif args.command == "list":
            backups = cli.list_backups(args.provider)
            if backups:
                print("Available backups:")
                for backup in backups:
                    provider = backup.get('provider', 'unknown')
                    mtime = backup.get('mtime', 0)
                    if isinstance(mtime, (int, float)):
                        mtime = datetime.fromtimestamp(mtime).isoformat()
                    print(f"  {backup['name']} - {backup.get('size', 0)} bytes - {mtime} ({provider})")
            else:
                print("No backups found")
        elif args.command == "test-providers":
            results = cli.test_providers()
            print(f"Provider test results: {results}")
        elif args.command == "download":
            success = cli.download_backup(args.backup_name, args.provider, args.to)
            if not success:
                sys.exit(1)
        elif args.command == "test-cycle":
            success = cli.test_backup_cycle(args.items)
            if not success:
                sys.exit(1)
        elif args.command == "list-providers":
            print("Available providers:")
            for provider_name in PROVIDERS.keys():
                status = "enabled" if provider_name in cli.providers else "disabled"
                if provider_name in ['google_cloud_storage']:
                    print(f"  {provider_name} ({status}) - Future development (currently disabled)")
                else:
                    print(f"  {provider_name} ({status})")
        elif args.command == "set-credentials":
            success = cli.set_provider_credentials(args.provider, args.username, args.password)
            if not success:
                sys.exit(1)
        elif args.command == "set-credentials-json":
            success = cli.set_provider_credentials_json(args.provider, args.json)
            if not success:
                sys.exit(1)
        elif args.command == "get-credentials":
            creds = cli.get_provider_credentials(args.provider)
            if creds:
                print(f"Provider: {args.provider}")
                print(f"Username: {creds['username']}")
                print(f"Password: {'*' * len(creds['password']) if creds['password'] else '(empty)'}")
            else:
                sys.exit(1)
        elif args.command == "list-keyman-services":
            cli.list_keyman_services()
        elif args.command == "remove-credentials":
            success = cli.remove_provider_credentials(args.provider)
            if not success:
                sys.exit(1)
        elif args.command == "test-keyman":
            success = cli.test_keyman_credentials(args.provider)
            if not success:
                sys.exit(1)
        elif args.command == "enable-provider":
            success = cli.enable_provider(args.provider)
            if not success:
                sys.exit(1)
        elif args.command == "disable-provider":
            success = cli.disable_provider(args.provider)
            if not success:
                sys.exit(1)
        elif args.command == "set-schedule":
            success = cli.set_backup_schedule(args.schedule)
            if not success:
                sys.exit(1)
        elif args.command == "get-schedule":
            cli.get_backup_schedule()
        elif args.command == "enable-schedule":
            success = cli.enable_backup_schedule(args.schedule)
            if not success:
                sys.exit(1)
        elif args.command == "disable-schedule":
            success = cli.disable_backup_schedule()
            if not success:
                sys.exit(1)
        elif args.command == "install":
            # Run environment setup
            try:
                from src.installer.setupEnvironment import BackupEnvironmentSetup
                setup = BackupEnvironmentSetup()
                success = setup.install()
                if not success:
                    sys.exit(1)
            except ImportError as e:
                print(f"ERROR: Could not import environment setup: {e}")
                sys.exit(1)
        elif args.command == "uninstall":
            # Run environment cleanup
            try:
                from src.installer.setupEnvironment import BackupEnvironmentSetup
                setup = BackupEnvironmentSetup()
                success = setup.uninstall()
                if not success:
                    sys.exit(1)
            except ImportError as e:
                print(f"ERROR: Could not import environment setup: {e}")
                sys.exit(1)
        elif args.command == "set-config":
            success = cli.set_provider_config(args.provider, args.key, args.value)
            if not success:
                sys.exit(1)
        elif args.command == "get-config":
            config = cli.get_provider_config(args.provider)
            if config:
                print(f"Configuration for {args.provider}:")
                for key, value in config.items():
                    if key in ['password', 'secret_key', 'application_key', 'encryption_key']:
                        value = '*' * len(str(value)) if value else '(empty)'
                    print(f"  {key}: {value}")
            else:
                sys.exit(1)
        elif args.command == "deploy-cron":
            success = cli.deploy_cron_job(args.schedule)
            if not success:
                sys.exit(1)
        elif args.command == "remove-cron":
            success = cli.remove_cron_job()
            if not success:
                sys.exit(1)
        elif args.command == "cron-status":
            cli.get_cron_job_status()
    
    except KeyboardInterrupt:
        print("\nOperation cancelled by user")
        sys.exit(1)
    except Exception as e:
        print(f"ERROR: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
